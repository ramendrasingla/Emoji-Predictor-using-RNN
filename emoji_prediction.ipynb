{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation, Bidirectional\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/train_emoji.csv',header=None)\n",
    "test = pd.read_csv('dataset/test_emoji.csv',header=None)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "\n",
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "                    \"3\": \":disappointed_face:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                    \"5\": \":hundred_points:\",\n",
    "                    \"6\": \":fire:\",\n",
    "                    \"7\": \":face_blowing_a_kiss:\",\n",
    "                    \"8\": \":chestnut:\",\n",
    "                    \"9\":\":flexed_biceps:\"\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤ï¸\n",
      "âš¾\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "ğŸ´\n",
      "ğŸ’¯\n",
      "ğŸ”¥\n",
      "ğŸ˜˜\n",
      "ğŸŒ°\n",
      "ğŸ’ª\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again ğŸ˜\n",
      "I am proud of your achievements ğŸ˜ƒ\n",
      "It is the worst day in my life ğŸ˜\n",
      "Miss you so much â¤ï¸\n",
      "food is life ğŸ´\n"
     ]
    }
   ],
   "source": [
    "data  = train.values\n",
    "for i in range(5):\n",
    "    print(data[i][0],emoji.emojize(emoji_dictionary[str(data[i][1])]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramendra/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ramendra/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = X_train[ix].split()\n",
    "    \n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = X_test[ix].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['food'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(sentences):\n",
    "    embedding_matrix = np.zeros((X_train.shape[0],10,50))\n",
    "    \n",
    "    for ix in range(sentences.shape[0]):\n",
    "        for ij in range(len(sentences[ix])):\n",
    "            embedding_matrix[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train = np.zeros((X_train.shape[0], 10, 50))\n",
    "embedding_matrix_test = np.zeros((X_test.shape[0], 10, 50))\n",
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(X_test.shape[0]):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        try:\n",
    "            embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]   \n",
    "        except:\n",
    "            embedding_matrix_test[ix][ij] = np.zeros((50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape,embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(LSTM(64, input_shape=(10,50), return_sequences=True,recurrent_dropout=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,input_shape=(10,50), return_sequences=False,recurrent_dropout=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 14 samples\n",
      "Epoch 1/200\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 1.5964 - acc: 0.2373 - val_loss: 1.5815 - val_acc: 0.2857\n",
      "Epoch 2/200\n",
      "118/118 [==============================] - 0s 270us/step - loss: 1.5675 - acc: 0.3729 - val_loss: 1.5889 - val_acc: 0.2143\n",
      "Epoch 3/200\n",
      "118/118 [==============================] - 0s 352us/step - loss: 1.5429 - acc: 0.3729 - val_loss: 1.5919 - val_acc: 0.2143\n",
      "Epoch 4/200\n",
      "118/118 [==============================] - 0s 320us/step - loss: 1.5206 - acc: 0.3814 - val_loss: 1.5935 - val_acc: 0.2143\n",
      "Epoch 5/200\n",
      "118/118 [==============================] - 0s 364us/step - loss: 1.4877 - acc: 0.3983 - val_loss: 1.5948 - val_acc: 0.2857\n",
      "Epoch 6/200\n",
      "118/118 [==============================] - 0s 331us/step - loss: 1.4555 - acc: 0.3898 - val_loss: 1.5944 - val_acc: 0.2857\n",
      "Epoch 7/200\n",
      "118/118 [==============================] - 0s 391us/step - loss: 1.4262 - acc: 0.3814 - val_loss: 1.5846 - val_acc: 0.2857\n",
      "Epoch 8/200\n",
      "118/118 [==============================] - 0s 371us/step - loss: 1.4358 - acc: 0.4153 - val_loss: 1.5728 - val_acc: 0.2857\n",
      "Epoch 9/200\n",
      "118/118 [==============================] - 0s 332us/step - loss: 1.3751 - acc: 0.4746 - val_loss: 1.5447 - val_acc: 0.1429\n",
      "Epoch 10/200\n",
      "118/118 [==============================] - 0s 271us/step - loss: 1.3341 - acc: 0.5169 - val_loss: 1.4988 - val_acc: 0.1429\n",
      "Epoch 11/200\n",
      "118/118 [==============================] - 0s 307us/step - loss: 1.3071 - acc: 0.4746 - val_loss: 1.4322 - val_acc: 0.2857\n",
      "Epoch 12/200\n",
      "118/118 [==============================] - 0s 355us/step - loss: 1.2208 - acc: 0.5763 - val_loss: 1.3765 - val_acc: 0.3571\n",
      "Epoch 13/200\n",
      "118/118 [==============================] - 0s 260us/step - loss: 1.1749 - acc: 0.5593 - val_loss: 1.3467 - val_acc: 0.3571\n",
      "Epoch 14/200\n",
      "118/118 [==============================] - 0s 303us/step - loss: 1.0769 - acc: 0.6271 - val_loss: 1.2638 - val_acc: 0.4286\n",
      "Epoch 15/200\n",
      "118/118 [==============================] - 0s 266us/step - loss: 1.0168 - acc: 0.6610 - val_loss: 1.2345 - val_acc: 0.4286\n",
      "Epoch 16/200\n",
      "118/118 [==============================] - 0s 359us/step - loss: 0.9806 - acc: 0.6610 - val_loss: 1.3295 - val_acc: 0.3571\n",
      "Epoch 17/200\n",
      "118/118 [==============================] - 0s 340us/step - loss: 0.8866 - acc: 0.6780 - val_loss: 1.1619 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "118/118 [==============================] - 0s 331us/step - loss: 0.8525 - acc: 0.7373 - val_loss: 1.0928 - val_acc: 0.5714\n",
      "Epoch 19/200\n",
      "118/118 [==============================] - 0s 300us/step - loss: 0.7787 - acc: 0.7542 - val_loss: 1.2544 - val_acc: 0.3571\n",
      "Epoch 20/200\n",
      "118/118 [==============================] - 0s 391us/step - loss: 0.6854 - acc: 0.7881 - val_loss: 1.0976 - val_acc: 0.5714\n",
      "Epoch 21/200\n",
      "118/118 [==============================] - 0s 317us/step - loss: 0.6856 - acc: 0.7966 - val_loss: 0.9302 - val_acc: 0.6429\n",
      "Epoch 22/200\n",
      "118/118 [==============================] - 0s 267us/step - loss: 0.6262 - acc: 0.7966 - val_loss: 1.1684 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "118/118 [==============================] - 0s 400us/step - loss: 0.6571 - acc: 0.7881 - val_loss: 1.3491 - val_acc: 0.5000\n",
      "Epoch 24/200\n",
      "118/118 [==============================] - 0s 373us/step - loss: 0.6664 - acc: 0.8051 - val_loss: 0.9710 - val_acc: 0.6429\n",
      "Epoch 25/200\n",
      "118/118 [==============================] - 0s 429us/step - loss: 0.5096 - acc: 0.8475 - val_loss: 0.7502 - val_acc: 0.7143\n",
      "Epoch 26/200\n",
      "118/118 [==============================] - 0s 367us/step - loss: 0.5058 - acc: 0.8475 - val_loss: 0.9161 - val_acc: 0.5714\n",
      "Epoch 27/200\n",
      "118/118 [==============================] - 0s 433us/step - loss: 0.4865 - acc: 0.8644 - val_loss: 1.3610 - val_acc: 0.4286\n",
      "Epoch 28/200\n",
      "118/118 [==============================] - 0s 434us/step - loss: 0.4058 - acc: 0.9237 - val_loss: 0.8760 - val_acc: 0.6429\n",
      "Epoch 29/200\n",
      "118/118 [==============================] - 0s 406us/step - loss: 0.4522 - acc: 0.8559 - val_loss: 0.7362 - val_acc: 0.6429\n",
      "Epoch 30/200\n",
      "118/118 [==============================] - 0s 386us/step - loss: 0.4520 - acc: 0.8559 - val_loss: 0.9576 - val_acc: 0.6429\n",
      "Epoch 31/200\n",
      "118/118 [==============================] - 0s 404us/step - loss: 0.3763 - acc: 0.8898 - val_loss: 0.8875 - val_acc: 0.6429\n",
      "Epoch 32/200\n",
      "118/118 [==============================] - 0s 407us/step - loss: 0.3479 - acc: 0.9068 - val_loss: 0.8427 - val_acc: 0.6429\n",
      "Epoch 33/200\n",
      "118/118 [==============================] - 0s 446us/step - loss: 0.3300 - acc: 0.9153 - val_loss: 1.2814 - val_acc: 0.5000\n",
      "Epoch 34/200\n",
      "118/118 [==============================] - 0s 383us/step - loss: 0.3409 - acc: 0.9068 - val_loss: 0.9052 - val_acc: 0.6429\n",
      "Epoch 35/200\n",
      "118/118 [==============================] - 0s 429us/step - loss: 0.3272 - acc: 0.9068 - val_loss: 0.6167 - val_acc: 0.7143\n",
      "Epoch 36/200\n",
      "118/118 [==============================] - 0s 369us/step - loss: 0.3631 - acc: 0.8814 - val_loss: 0.7664 - val_acc: 0.7143\n",
      "Epoch 37/200\n",
      "118/118 [==============================] - 0s 394us/step - loss: 0.2754 - acc: 0.9237 - val_loss: 0.9100 - val_acc: 0.7143\n",
      "Epoch 38/200\n",
      "118/118 [==============================] - 0s 325us/step - loss: 0.2324 - acc: 0.9237 - val_loss: 0.7359 - val_acc: 0.7143\n",
      "Epoch 39/200\n",
      "118/118 [==============================] - 0s 337us/step - loss: 0.2672 - acc: 0.8898 - val_loss: 0.6970 - val_acc: 0.7857\n",
      "Epoch 40/200\n",
      "118/118 [==============================] - 0s 330us/step - loss: 0.2140 - acc: 0.9153 - val_loss: 0.7212 - val_acc: 0.7143\n",
      "Epoch 41/200\n",
      "118/118 [==============================] - 0s 340us/step - loss: 0.2188 - acc: 0.9068 - val_loss: 0.7907 - val_acc: 0.6429\n",
      "Epoch 42/200\n",
      "118/118 [==============================] - 0s 337us/step - loss: 0.2411 - acc: 0.9153 - val_loss: 0.9074 - val_acc: 0.5714\n",
      "Epoch 43/200\n",
      "118/118 [==============================] - 0s 348us/step - loss: 0.1840 - acc: 0.9576 - val_loss: 0.9187 - val_acc: 0.5714\n",
      "Epoch 44/200\n",
      "118/118 [==============================] - 0s 348us/step - loss: 0.1910 - acc: 0.9322 - val_loss: 0.7369 - val_acc: 0.6429\n",
      "Epoch 45/200\n",
      "118/118 [==============================] - 0s 370us/step - loss: 0.2359 - acc: 0.9322 - val_loss: 0.7914 - val_acc: 0.6429\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint # save the best model, fight overfiitting\n",
    "from keras.callbacks import EarlyStopping #save time\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc',patience=1)\n",
    "\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 200, batch_size=32,shuffle=True,validation_split=0.1,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 0 2 2 3 2 4 2 1 2 0 0 1 3 2 2 3 2 0 0 4 0 3 3 2 0 4 2 0 1 0 2 0 1 2\n",
      " 4 4 2 1 0 0 1 2 2 2 2 0 3 3 0 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(pred==t))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428571"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "t = np.array(test[1])\n",
    "float(sum(pred==t))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat \n",
      "ğŸ´ \t ğŸ´\n",
      "he did not answer \n",
      "ğŸ˜ \t ğŸ˜\n",
      "he got a raise \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "she got me a present \n",
      "â¤ï¸ \t â¤ï¸\n",
      "ha ha ha it was so funny \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "he is a good friend \n",
      "ğŸ˜ƒ \t â¤ï¸\n",
      "I am upset \n",
      "ğŸ˜ \t â¤ï¸\n",
      "We had such a lovely dinner tonight \n",
      "ğŸ˜ƒ \t â¤ï¸\n",
      "where is the food \n",
      "ğŸ´ \t ğŸ´\n",
      "Stop making this joke ha ha ha \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "where is the ball \n",
      "âš¾ \t âš¾\n",
      "work is hard \n",
      "ğŸ˜ƒ \t ğŸ˜\n",
      "This girl is messing with me \n",
      "â¤ï¸ \t ğŸ˜\n",
      "are you serious ha ha \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "Let us go play baseball \n",
      "âš¾ \t âš¾\n",
      "This stupid grader is not working \n",
      "ğŸ˜ \t ğŸ˜\n",
      "work is horrible \n",
      "ğŸ˜ \t ğŸ˜\n",
      "Congratulation for having a baby \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "stop messing around \n",
      "ğŸ˜ \t ğŸ˜\n",
      "any suggestions for dinner \n",
      "ğŸ˜ƒ \t ğŸ´\n",
      "I love taking breaks \n",
      "â¤ï¸ \t â¤ï¸\n",
      "you brighten my day \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "I boiled rice \n",
      "ğŸ´ \t ğŸ´\n",
      "she is a bully \n",
      "â¤ï¸ \t ğŸ˜\n",
      "Why are you feeling bad \n",
      "ğŸ˜ \t ğŸ˜\n",
      "I am upset \n",
      "ğŸ˜ \t ğŸ˜\n",
      "I worked during my birthday \n",
      "ğŸ˜ƒ \t ğŸ˜\n",
      "My grandmother is the love of my life \n",
      "â¤ï¸ \t â¤ï¸\n",
      "enjoy your break \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "valentine day is near \n",
      "ğŸ˜ƒ \t â¤ï¸\n",
      "I miss you so much \n",
      "â¤ï¸ \t â¤ï¸\n",
      "throw the ball \n",
      "âš¾ \t âš¾\n",
      "My life is so boring \n",
      "ğŸ˜ \t ğŸ˜\n",
      "she said yes \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "will you be my valentine \n",
      "ğŸ˜ \t â¤ï¸\n",
      "he can pitch really well \n",
      "âš¾ \t âš¾\n",
      "dance with me \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "I am starving \n",
      "ğŸ´ \t ğŸ´\n",
      "See you at the restaurant \n",
      "ğŸ´ \t ğŸ´\n",
      "I like to laugh \n",
      "â¤ï¸ \t ğŸ˜ƒ\n",
      "I will go dance \n",
      "âš¾ \t ğŸ˜ƒ\n",
      "I like your jacket \n",
      "â¤ï¸ \t ğŸ˜ƒ\n",
      "i miss her \n",
      "â¤ï¸ \t â¤ï¸\n",
      "what is your favorite baseball game \n",
      "âš¾ \t âš¾\n",
      "Good job \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "I love to the stars and back \n",
      "ğŸ˜ƒ \t â¤ï¸\n",
      "What you did was awesome \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "ha ha ha lol \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "I want to joke \n",
      "ğŸ˜ \t ğŸ˜ƒ\n",
      "go away \n",
      "ğŸ˜ \t ğŸ˜\n",
      "yesterday we lost again \n",
      "ğŸ˜ \t ğŸ˜\n",
      "family is all I have \n",
      "ğŸ˜ \t â¤ï¸\n",
      "you are failing this exercise \n",
      "ğŸ˜ \t ğŸ˜\n",
      "Good joke \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "You totally deserve this prize \n",
      "ğŸ˜ƒ \t ğŸ˜ƒ\n",
      "I did not have breakfast \n",
      "ğŸ˜ \t ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "for e in range(pred.shape[0]):\n",
    "    st = ''\n",
    "    for ix in X_test[e]:\n",
    "        st+=ix + ' '\n",
    "    print(st)\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[e])]),'\\t',emoji.emojize(emoji_dictionary[str(t[e])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
